{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SC23 Tutorial: Efficient Distributed GPU Programming for Exascale\n",
        "\n",
        "-   Time: Monday, 13 November 2023 8:30 - 17:00 MST\n",
        "-   Location: 405, Denver Congress Centre, USA\n",
        "-   Program Link:\n",
        "    https://sc23.supercomputing.org/presentation/?id=tut140&sess=sess242\n",
        "    \\## Hands-On 6: Overlap Communication and Computation with MPI\n",
        "\n",
        "You are now going to apply the concepts you learned in the lectures 4\n",
        "and 5: Using profiling tools, and applying them to implement overlapping\n",
        "MPI with GPU kernels.\n",
        "\n",
        "Compile with\n",
        "\n",
        "``` bash\n",
        "make\n",
        "```\n",
        "\n",
        "Submit your compiled application to the batch system with\n",
        "\n",
        "``` bash\n",
        "make run\n",
        "```\n",
        "\n",
        "Study the performance by glimpsing at the profile generated with\n",
        "`make profile`. For `make run` and `make profile` the environment\n",
        "variable `NP` can be set to change the number of processes.\n",
        "\n",
        "### Task 0: Profile the non-overlap MPI-CUDA version of the code\n",
        "\n",
        "Use the Nsight System profiler to profile the starting point version\n",
        "non-Overlap MPI jacobi solver. The objective is to become familiar in\n",
        "navigating the GUI identify possible areas to overlap computation and\n",
        "communication.\n",
        "\n",
        "1.  Start by compiling and running the application with `make run`\n",
        "2.  Record an Nsight Systems profile, using the appropriate Makefile\n",
        "    target (`make profile`)\n",
        "3.  Open the recorded profile in the GUI\n",
        "    -   Either: Install Nsight Systems locally, and transfer the\n",
        "        .qdrep/.nsys-rep file\n",
        "    -   Or: By running Xpra in your browser: In Jupyter, select “File \\>\n",
        "        New Launcher” and “Xpra Desktop”, which will open in a new tab.\n",
        "        Don’t forget to source the environment in your `xterm`.\n",
        "4.  Familiarize yourself with the different rows and the traces they\n",
        "    represent.\n",
        "    -   See if you can correlate a CUDA API kernel launch call and the\n",
        "        resulting kernel execution on the device\n",
        "5.  Follow the lecture steps and identify the relevant section with\n",
        "    overlap potential in your code\n",
        "    -   Hint: Try navigating with the NVTX ranges.\n",
        "\n",
        "### Task 1: Implement Communication/Computation overlap\n",
        "\n",
        "Realize the optimization potential you discovered in the previous task\n",
        "and reduce the whitespace between kernel calls on the GPU profile by\n",
        "implementing communication/computation overlap.\n",
        "\n",
        "You will need to separately calculate the boundary, and you should use\n",
        "high-priority streams. A less efficient (problem size-dependent)\n",
        "alternative to high-priority streams would be to launch the boundary\n",
        "processing kernels before the bulk kernel. regions for the halo\n",
        "exchange.\n",
        "\n",
        "The starting point of this task is the non-overlapping MPI variant of\n",
        "the Jacobi solver. Follow the `TODO`s in `jacobi.cpp`:\n",
        "\n",
        "-   Query the priority range to be used by the CUDA streams\n",
        "-   Create new top and bottom CUDA streams and corresponding CUDA events\n",
        "-   Initialize all streams using priorities\n",
        "-   Modify the original call to `launch_jacobi_kernel` to not compute\n",
        "    the top and bottom regions\n",
        "-   Add additional calls to `launch_jacobi_kernel` for the top and\n",
        "    bottom regions using the high-priority streams\n",
        "-   Wait on both top and bottom streams when calculating the norm\n",
        "-   Synchronize top and bottom streams before applying the periodic\n",
        "    boundary conditions using MPI\n",
        "-   Destroy the additional cuda streams and events before ending the\n",
        "    application"
      ],
      "id": "02d50eab-6f3d-4b5d-8743-4032717ba48f"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  }
}
