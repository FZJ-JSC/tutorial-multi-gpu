{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SC21 Tutorial: Efficient Distributed GPU Programming for Exascale\n",
        "\n",
        "-   Time: Sunday, 14 November 2021 8AM - 5PM CST\n",
        "-   Location: *online*\n",
        "-   Program Link:\n",
        "    https://sc21.supercomputing.org/presentation/?id=tut138&sess=sess188\n",
        "\n",
        "## Hands-On 8-NVSHMEM: Host-initiated Communication with NVSHMEM\n",
        "\n",
        "### Task: Using NVSHMEM device API\n",
        "\n",
        "#### Description\n",
        "\n",
        "The purpose of this task is to use the NVSHMEM host API instead of MPI\n",
        "to implement a multi-GPU jacobi solver. The starting point of this task\n",
        "is the MPI variant of the jacobi solver. You need to work on `TODOs` in\n",
        "`jacobi.cu`:\n",
        "\n",
        "-   Initialize NVSHMEM:\n",
        "    -   Include NVSHMEM headers.\n",
        "    -   Initialize NVSHMEM using `MPI_COMM_WORLD`.\n",
        "    -   Allocate work arrays `a` and `a_new` from the NVSHMEM symmetric\n",
        "        heap. Take care of passing in a consistent size!\n",
        "    -   Calculate halo/boundary row index of top and bottom neighbors.\n",
        "    -   Add necessary inter PE synchronization.\n",
        "    -   Replace MPI periodic boundary conditions with\n",
        "        `nvshmemx_float_put_on_stream` to directly push values needed by\n",
        "        top and bottom neighbors.\n",
        "    -   Deallocate memory from the NVSHMEM symetric heap.\n",
        "    -   Finalize NVSHMEM before existing the application\n",
        "\n",
        "Compile with\n",
        "\n",
        "``` bash\n",
        "make\n",
        "```\n",
        "\n",
        "Submit your compiled application to the batch system with\n",
        "\n",
        "``` bash\n",
        "make run\n",
        "```\n",
        "\n",
        "Study the performance by glimpsing at the profile generated with\n",
        "`make profile`. For `make run` and `make profile` the environment\n",
        "variable `NP` can be set to change the number of processes. \n",
        "\n",
        "#### Note\n",
        "\n",
        "The Slurm installation on JUWELS-Booster sets `CUDA_VISIBLE_DEVICES`\n",
        "automatically so that each spawned process only sees the GPU it should\n",
        "use (see [GPU Devices](https://apps.fz-juelich.de/jsc/hps/juwels/booster-overview.html#gpu-devices)\n",
        "in the JUWELS Booster Overview documentation). This is not supported for\n",
        "NVSHMEM. The automatic setting of `CUDA_VISIBLE_DEVICES` can be disabled\n",
        "by setting `CUDA_VISIBLE_DEVICES=0,1,2,3` in the shell that executes srun.\n",
        "With `CUDA_VISIBLE_DEVICES` set all spawned processes can see all GPUs\n",
        "listed. This is automatically done for the `sanitize`, `run` and\n",
        "`profile` make targets.\n",
        "\n",
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  }
}
